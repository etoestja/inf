\documentclass[a4paper]{article}
\usepackage[a4paper, left=5mm, right=5mm, top=5mm, bottom=5mm]{geometry}
%\geometry{paperwidth=210mm, paperheight=2000pt, left=5pt, top=5pt}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{indentfirst}
\usepackage{tikz}
\usetikzlibrary{automata,positioning,arrows}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{amssymb}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{wasysym}
\title{Статистическое обучение\\Задание 1}
\date{задано 2017.02.19}
\author{Сергей~Володин, 374 гр.}
\newcommand{\matrixl}{\left|\left|}
\newcommand{\matrixr}{\right|\right|}

\newcommand{\peq}{\mathrel{+}=}
\newcommand{\meq}{\mathrel{-}=}
\newcommand{\deq}{\mathrel{:}=}
\newcommand{\plpl}{\mathrel{+}+}

% пустое слово
\def\eps{\varepsilon}

% регулярные языки
\def\eqdef{\overset{\mbox{\tiny def}}{=}}
\newcommand{\niton}{\not\owns}

\begin{document}
\maketitle
\section*{Упражнение 1}
\begin{enumerate}
\item Неравенство Маркова: Если $X\geqslant 0$, то $P(X\geqslant \eps)\leqslant \frac{\mathbb{E}X}{\eps}$. Нужно: $P(X\geqslant \eps)=\frac{\mathbb{E}X}{\eps}$. Найдем $P(X<\eps)=1-\frac{\mathbb{E}X}{\eps}$, $f_X(x)=\frac{\mathbb{E}X}{x^2}$. Тогда $\mathbb{E}X=\int\limits_0^\infty xf_X(x)dx=\int\limits_0^\infty \mathbb{E}X\frac{dx}{x}$. Поскольку интеграл $\int\limits_0^\infty\frac{dx}{x}$ расходится, то $\mathbb{E}X=0$. Значит, $\boxed{X=0}$. Проверим: $0=P(0\geqslant\eps)=\frac{0}{\eps}\blacksquare$
\item Неравенство Чебышева: $P(|X-\mathbb{E}X|\geqslant a)\leqslant \frac{\sigma^2}{a^2}$. Если обозначить $\eta=|X-\mathbb{E}X|^2$, то получим неравенство Маркова. Возьмем предыдущий пример $\Rightarrow$ $\eta=0$ $\Rightarrow$ $X=c$ (константа). Проверим: $0=P(0\geqslant a)=\frac{0}{a^2}$ (для константы $\sigma=0$) $\blacksquare$
\end{enumerate}
\section*{Упражнение 2.1}
Имеем: $Y\geqslant 0$~--- случайная величина, числа $A\geqslant 2$, $B>0$. $\forall \eps\geqslant 0\hookrightarrow P(Y\geqslant \eps)\leqslant A\exp(-\frac{\eps^2}{B^2})$.

\begin{enumerate}
\item Оценим $\mathbb{E}e^{\lambda Y^2}=1+\int\limits_1^\infty P(e^{\lambda Y^2}>x)dx$. Перепишем $e^{\lambda Y^2}>x\Leftrightarrow \lambda Y^2>\ln x\Leftrightarrow Y>\sqrt{\frac{\ln x}{\lambda}}$. Значит, $\mathbb{E}e^{\lambda Y^2}\leqslant 1+A\int\limits_1^\infty x^{-1/\lambda B^2}dx=1+A\frac{1}{1/\lambda B^2-1}$ при условии $\lambda\in(0,1/B^2)$. Берём $\lambda=1/2B^2$. Тогда $\mathbb{E}e^{\lambda Y^2}\leqslant 1+A\leqslant 2A$ при $A\geqslant 2$
\item $\mathbb{E}Y=\sqrt{\frac{1}{\lambda}\ln e^{\lambda (\mathbb{E}Y)^2}}\underbrace{\leqslant}_{\mbox{\small Йенс. } e^{\lambda x^2}}\sqrt{\frac{1}{\lambda}\ln \mathbb{E}e^{\lambda Y^2}}\underbrace{\leqslant}_{(1)}\sqrt{2B^2\ln 2A}=\sqrt{2}B\sqrt{\ln 2A}$. Заметим, что при $A\geqslant 2$, $\sqrt{\ln 2A}\leqslant \sqrt{2\ln A}$. Тогда $\mathbb{E}Y\leqslant \boxed{2B\sqrt{\ln A}}$. То есть, проведено доказательство для $C=2$.
\end{enumerate}
\section*{Упражнение 2.2}
Имеем: $Y\geqslant 0$~--- случайная величина, числа $A\geqslant 2$, $B>0$. $\forall \eps\geqslant 0\hookrightarrow P(Y\geqslant \eps)\leqslant A\exp(-\frac{\eps}{B})$.
\begin{enumerate}
\item Оценим $\mathbb{E}e^{\lambda Y}=1+\int\limits_1^\infty P(e^{\lambda Y}>x)dx$. Рассмотрим $e^{\lambda Y}>x\Leftrightarrow Y>\frac{\ln x}{\lambda}$. $P(Y>\frac{\ln x}{\lambda})\leqslant Ae^{-\frac{\ln x}{\lambda B}}=Ax^{-1/\lambda B}$. Тогда $\mathbb{E}e^{\lambda Y}\leqslant 1+A\int\limits_1^\infty x^{-1/\lambda B}dx$ при $\lambda B<1$. Берем $\lambda=1/2B$. Тогда $\mathbb{E}e^{\lambda Y}\leqslant 1+A\leqslant 2A$
\item $\mathbb{E}Y=\frac{1}{\lambda}\ln e^{\lambda \mathbb{E}Y}\leqslant \frac{1}{\lambda}\ln \mathbb{E} e^{\lambda Y}\leqslant \frac{1}{\lambda}2A=2B\ln 2A\leqslant \boxed{4B\ln A}$
\end{enumerate}
\section*{Упражнение 3}
Случайная величина $X$~--- субгауссовская с параметром $\sigma$ $\Leftrightarrow$ $\mathbb{E}e^{\lambda X}\leqslant e^{\frac{\lambda^2\sigma^2}{2}}$.

Пусть $X_1,\,X_2$~--- субгауссовские с параметрами $\sigma_1$ и $\sigma_2$. $Y=X_1+X_2$. Доказать: $Y$~--- субгауссовская для некоторого $\sigma$.

Рассмотрим $\mathbb{E}e^{\lambda Y}=\mathbb{E}e^{\lambda (X_1+X_2)}\leqslant \mathbb{E} e^{2\lambda\max X_i}=\mathbb{E}\max e^{2\lambda X_i}\leqslant \mathbb{E} \sum e^{2\lambda X_i}\leqslant 2$
\section*{Упражнение 3.2}
Пусть $X\sim N(0,1)$. Тогда $X$~--- субгауссовская с параметром $1$. Определим $X_1=X$, $X_2=X$~--- две субгауссовские величины. Определим $Y=X_1X_2$. Но $\mathbb{E}Y=\mathbb{E}X^2=1\neq 0$, значит, $Y$ \underline{не может быть субгауссовской}
\section*{Упражнение 3.3}
Обозначим $f(\lambda)=\mathbb{E}e^{\lambda X}$, $g(\lambda)=e^(\sigma^2\lambda^2/2)$. $f(\lambda)=\sum\limits_{k=0}^\infty \frac{\lambda^k}{k!}\mathbb{E}X^k=1+\lambda \mathbb{E}X+\frac{\lambda^2}{2}\mathbb{E}X^2+...$. Значит, $f'(0)=\mathbb{E}X$. Найдём $g'(\lambda)=\lambda g(\lambda)$. Найдём $f(0)=g(0)=1$. Значит, $g'(0)=0$. Обозначим $h(\lambda)=f(\lambda)-g(\lambda)$. По условию, $h(\lambda)\leqslant 0$. Поскольку $h(0)=0$, то $h'(0)=0$. Но $h'(0)=f'(0)-g'(0)=\mathbb{E}X$. Значит, $\boxed{\mathbb{E}X=0}$
\section*{Упражнение 3.4}
\section*{Упражнение 4.1}
Плотность нормального распределения: $\psi(x)=f_{N(0,1)}(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}$. Тогда $\frac{d}{dx}\psi(x)=\frac{1}{\sqrt{2\pi}}(-2x/2)e^{-\frac{x^2}{2}}=-x\psi(x)$.

Значит, $\boxed{x\psi(x)+\psi'(x)=0}$
\section*{Упражнение 4.2}
Обозначим $f_1(x)=\psi(x)(1/x-1/x^3)$, $f_2(x)=P(X\geqslant x)=\int\limits_x^\infty\psi(t)dt$, $f_3(x)=\psi(x)(1/x-1/x^3+3/x^5)$. Доказать: при $x>0$ $f_1\leqslant f_2\leqslant f_3$. Обозначим $g(x)=f_2(x)-f_1(x)$, $h(x)=f_3(x)-f_2(x)$ Нужно доказать, что $g,h\geqslant 0$.

Рассмотрим $g'(x)=-\frac{3\psi(x)}{x^4}$, $h'(x)=-\frac{15\psi(x)}{x^6}$
\section*{Упражнение 4.3}
Рассмотрим $P(X\geqslant x)\leqslant\inf\limits_{\lambda > 0}\frac{\mathbb{E}e^{\lambda X}}{e^{\lambda x}}$. Для нормальной случайной величины $\mathbb{E}e^{\lambda X}=e^{\frac{\lambda^2\sigma^2}{2}}=e^{\frac{\lambda^2}{2}}$. Значит, $\frac{\mathbb{E}e^{\lambda X}}{e^{\lambda x}}=\exp(\frac{\lambda^2}{2}-\lambda x)\to\min\limits_{\lambda > 0}$. Находим $\lambda^*=x>0$, получаем $P(X\geqslant x)\leqslant \exp(-\frac{x^2}{2})$
\section*{Упражнение 4.4}
\begin{enumerate}
\item Теорема Муавра-Лапласа: $P(\frac{x-np}{\sqrt{npq}}\geqslant x)\to\int\limits_x^\infty \psi(t)dt$
\item Неравенство Хёффдинга. Рассмотрим $\xi=\sum\limits_{i=1}^n \xi_i$, $\{\xi_i\}$~--- i.i.d., $\xi_i=\begin{cases}
1,&p\\
0,&1-p
\end{cases}$. Обозначим $\zeta_i=\xi_i-p$. Тогда $\mathbb{E}\zeta_i=0$. $\zeta_i\in[-p,1+p]$. Значит, $\zeta_i$~--- субгауссовская с $\sigma^2=1/2$. Рассмотрим $P(\sum \xi_i-np\geqslant \eps=P(\sum \zeta_i\geqslant \eps)\leqslant e^{-\frac{\eps^2}{2\cdot 1/4}}=e^{-2\eps^2}$
\item Сравнение при разных $p$ ???
\end{enumerate}
\section*{Упражнение 5.1}
$f^*=\argmin\limits_{f\in Y^X} L(f)$. $L(f)=\mathbb{E}_{X\times Y}[f(X)\neq Y]=\mathbb{E}_X\mathbb{E}_{Y|X}[f(X)\neq Y]=\mathbb{E}_X P(f(X)\neq Y\big| X)$. Фиксируем $X$, т.е. рассмотрим одно слагаемое (или подынтегральный член):

$P(f(X)\neq Y\big|X)=P(f=1\big| X,Y=-1)P(Y=-1\big|X)+P(f=-1\big| X,Y=1)P(Y=1\big|X)\boxed{=}$. Поскольку $f$ зависит только от $X$, $\boxed{=}[f(X)=1]P(Y=-1\big|X)+[f(X)=-1]P(Y=1\big|X)$. В этой сумме одна из скобок $[f(X)=\cdot]$ равна 1, а другая 0, в зависимости от значения $f$ на $X$. Значит, для минимизации $\mathbb{E}_{Y|X}[f(X)\neq Y]$ нужно взять $f(X)=\argmin\limits_j P(Y=j\big|X)$

Рассмотрим $\eta(x)=\mathbb{E}[Y|X=x]=P(Y=1\big|X=x)-P(Y=-1\big| X=x)$. Значит, $\mbox{sign}\,\eta(x)=\argmin\limits_j P(Y=j\big| X=x)$, то есть, $f^*(x)=\mbox{sign}\,\eta(x)$ $\blacksquare$
\section*{Упражнение 5.2}
Фиксируем $x$. Обозначим $p=P(Y=+1|X=x)$. Тогда $\eta(x)=P(Y=+1|X=x)-P(Y=-1|X=x)=p-(1-p)=2p-1$. Знаем, что $|2p-1|\geqslant h$. Значит, либо $p\geqslant\frac{h+1}{2}$, либо $p\leqslant \frac{1-h}{2}$

Поскольку $f^*=\mbox{sign}(2p-1)$, то $[f^*=+1]=[p>0.5]$, а $[f^*=-1]=[p<0.5]$

Рассмотрим $L(f^*)=\mathbb{E}_X\left(\underbrace{[p>0.5](1-p)+[p<0.5]p}_{l(x)}\right)$.

\begin{enumerate}
\item Пусть $p>0.5$. Но тогда $p\geqslant \frac{1+h}{2}$. Значит, $l(x)\leqslant 1-p=\frac{1-h}{2}$
\item Пусть $p<0.5$. Тогда $p\leqslant \frac{1-h}{2}$. Значит, $l(x)\leqslant p=\frac{1-h}{2}$
\end{enumerate}

Получаем, что $l(x)\leqslant \frac{1-h}{2}$. Тогда $L(f^*)=\mathbb{E}_Xl(x)\leqslant \frac{1-h}{2}$ $\blacksquare$
\section*{Задача 1}
Имеем $Y=\{-1,1\}$~--- метки классов, $K$~--- класс функций, $f^*=\argmin\limits_{f\in Y^X} L(f)$. Рассмотрим элементы $x_1,x_2,x_3\in X$. Их вероятноси $P(x_i)=0$.

Определим $f_i(x)=\begin{cases}
\overline{f^*(x)},&x\neq x_i\\
f^*(x),&x=x_i
\end{cases}$

Определим $F={f^*, \overline{f^*}, f_1, f_2, f_3}$.

\begin{enumerate}
\item Halving (большинство). Рассмотрим произвольный $x\in X$ (первый шаг алгоритма). Если $x=x_i$, то получим значения функций $(f^*, \overline{f^*}, \overline{f^*},f^*,\overline{f^*})$. Halving выдаст неверный ответ (3>2), то есть, $\overline{f^*}$. Если $x\neq x_i$, то получим значения функций $(f^*, \overline{f^*}, \overline{f^*},\overline{f^*},\overline{f^*})$. Halving снова выдаст неверный ответ.
\item Меньшинство. В 
\end{enumerate}
\section*{Задача 2}
Конспект 1-е занятие
\end{document}