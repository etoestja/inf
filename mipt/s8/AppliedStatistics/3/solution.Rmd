---
title: 'Прикладная статистика. Задание 3: линейная регрессия'
output:
  html_document: default
  html_notebook: default
---

**Володин Сергей**, группа 374

**Цель:** построить линейную регрессию вещественного отклика L10 от признаков

#### 1. Функция, строящая графики остатков от признаков для модели m
```{r}
visualize_model <- function(m, data_)
{
  par(mfrow=c(4,2))
  
  qqnorm(residuals(m))
  qqline(residuals(m), col="red")
  grid()
  
  plot(1:nrow(data_), rstandard(m), xlab="i", ylab="Standardized residuals", pch=19)
  addtrend(1:nrow(data_), rstandard(m))
  grid()
  
  plot(fitted(m), rstandard(m), xlab="Fitted values", ylab="Standardized residuals", pch=19)
  addtrend(fitted(m), rstandard(m))
  grid()
  
  for(i in c(1,2,3,4,5))
  {
    plot(as.numeric(data_[,i]), rstandard(m), xlab=colnames(data_)[i], ylab="Standardized residuals", pch=19)
    if(length(levels(as.factor(data_[,i])))>3)
    {
      addtrend(as.numeric(data_[,i]), rstandard(m))
    }
    grid()
  }
}

addtrend <- function(x, y){
  y <- y[order(x)]
  x <- sort(x)  
  lines(x, predict(loess(y ~ x), x), col = "red")
}
```


#### 2. Загрузка данных
```{r message=FALSE}
library(gdata)
library(lattice)
library(lmtest)
library(MASS)
data_orig <- read.xls("bearing.xlsx")
```

#### 3. Столбцы матрицы объект-признак:
```{r}
colnames(data_orig)
```

#### 4. Число уровней для каждого столбца
```{r}
cat(sprintf("Rows:\t\t%d\n", nrow(data_orig)))
L = length(levels(as.factor(data_orig[,1])))
cat(sprintf("%s:\t\t%d values\n", colnames(data_orig[1]), L))
for(i in 2:length(colnames(data_orig)))
{
  L = length(levels(as.factor(data_orig[,i])))
  cat(sprintf("%s:\t%d values\n", colnames(data_orig[i]), L))
}
```

Отклик L10 -- вещественный.

Имеющиеся признаки:

* "Производитель" -- категориальный
* "Нагрузка" -- вещественный
* "Число.шаров" -- вещественный
* "Диаметр" -- вещественный
* "Тип.подшипника" -- категориальный

```{r}
data = data_orig
data$L10 = data_orig$L10
data$Производитель <- as.factor(data_orig$Производитель)
data$Нагрузка = data_orig$Нагрузка
data$Число.шаров <- data_orig$Число.шаров
data$Диаметр <- data_orig$Диаметр
data$Тип.подшипника <- as.factor(data_orig$Тип.подшипника)
summary(data)
```

#### 5. Распределение признаков
```{r fig.height=10, fig.width=10}
par(mfrow=c(3, 2), mar=c(4, 2, 2, 1))
for(i in 1:6)
{
  hist(as.numeric(data_orig[,i]), xlab = colnames(data)[i], main = "")
}
```

```{r fig.height=10, fig.width=10}
panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}

pairs(~., data=data, diag.panel = panel.hist)
```

#### 6. Оценка наличия выбросов
```{r fig.height=10, fig.width=10}
par(mfrow=c(6,1), mar=c(4, 2, 2, 1))
for(i in 1:6)
{
  boxplot(data_orig[,i], xlab = colnames(data)[i], horizontal = TRUE)
}
```

Уберём слишком большие значения по диаметру и нагрузке:
```{r}
data = data[!(data$Диаметр<0.25 | data$Диаметр>0.75),]
hist(data$Диаметр)
```
```{r}
data = data[!(data$Нагрузка>5000),]
hist(data$Нагрузка)
```
```{r}
data = data[!(data$L10>40),]
hist(data$L10, breaks=50)
```


```{r fig.height=10, fig.width=10}
pairs(~., data=data, diag.panel = panel.hist)
```
```{r}
library(car)
scatterplotMatrix(~L10+Диаметр+Нагрузка|Тип.подшипника, data=data)
```


#### 7. Рассмотрим отклик: переменную L10
```{r}
boxplot(data$L10, horizontal = TRUE, xlab = colnames(data)[1])
```

Разница:
$\frac{\max L_{10}}{\min L_{10}}=$ `r round(max(data$L10)/min(data$L10))` $>10$

Метод Бокса-Кокса
```{r}
par(mfrow=c(1,1))
boxcox(lm(L10~., data=data))
```

Берём $\lambda=\frac{1}{2}$, то есть, корень из L10

```{r}
data$newL10 <- sqrt(data$L10)
data$L10 <- NULL
```


#### 8. Проведём анализ остатков
Сначала построим модель, использующую все признаки:
```{r}
m1 <- lm(data$newL10 ~., data=data)
```

```{r echo=FALSE}
shapiro.test(residuals(m1))$p.value
t.test(residuals(m1))$p.value
as.numeric(bptest(m1)$p.value)
```

Критерий     |                  |p  
----------   | -----------------|---------
Шапиро-Уилка |нормальность      |`r shapiro.test(residuals(m1))$p.value`
Стьюдента    |несмещенность     |`r t.test(residuals(m1))$p.value`
Бройша-Пагана|гомоскедастичность|`r bptest(m1)$p.value`

Остатки:

* Нормальные, поэтому используем критерий Стьюдента
* Несмещенные
* Гомоскедастичные

### 9. Отбор признаков
```{r}
summary(m1)
```
Тип подшипника, число шаров не значимы
```{r fig.height=10, fig.width=10, warning=FALSE}
visualize_model(m1, data)
```

Анализ необходимости добавления взаимодействий и квадратов признаков
Посмотрим на попарные взаимодействия:
```{r}
add1(m1, ~ .^2, test="F")
```

Добавляем: Производитель:Нагрузка, Производитель:Диаметр, Нагрузка:Диаметр, Нагрузка:Тип.подшипника, Диаметр:Тип.подшипника
Удаляем: число шаров

```{r}
m2 <- lm(newL10 ~ Нагрузка + Диаметр + Производитель:Нагрузка + Производитель:Диаметр + Нагрузка:Диаметр + Нагрузка:Тип.подшипника + Диаметр:Тип.подшипника, data=data)
```


```{r fig.height=10, fig.width=10, warning=FALSE}
visualize_model(m2, data = data)
```

```{r}
summary(m2)
```
```{r}
jtest(m1,m2)
```
m2 лучше m1.

Удалим Производитель:Диаметр

```{r}
m3 <- lm(newL10 ~ Нагрузка + Диаметр + Производитель:Нагрузка  + Нагрузка:Диаметр + Нагрузка:Тип.подшипника + Диаметр:Тип.подшипника, data=data)
```

```{r}
jtest(m2,m3)
```
Модель стала лучше
```{r}
summary(m3)
```
```{r fig.height=10, fig.width=10, warning=FALSE}
visualize_model(m3, data = data)
```
Нет изменений в характере остатков:
```{r}
shapiro.test(residuals(m3))$p.value
t.test(residuals(m3))$p.value
as.numeric(bptest(m3)$p.value)
```
Удаление зависимости от типа подшипника:

```{r}
m4 <- lm(newL10 ~ Нагрузка + Диаметр + Производитель:Нагрузка + Нагрузка:Диаметр, data=data)
```

```{r fig.height=10, fig.width=10, warning=FALSE}
visualize_model(m4, data = data)
```
```{r}
summary(m4)
```
Теперь все признаки значимы.


#### 10. Расчёт расстояний Кука
```{r}
par(mfrow=c(1,2))
plot(fitted(m4), cooks.distance(m4), xlab="Fitted SqrtL10", ylab="Cook's distance")
lines(c(0,100), c(0.015, 0.015), col="red")
plot(data$newL10, cooks.distance(m4), xlab="SqrtL10", ylab="Cook's distance")
lines(c(0,100), c(0.015, 0.015), col="red")
```

Удалим наблюдения с расстоянием Кука больше 0.015
```{r, echo=FALSE}
cd = cooks.distance(m4)<=0.015
data2 <- data[cd & !is.na(cd),]
rownames(data2) <- 1:nrow(data2)
m5 <- lm(newL10 ~ Нагрузка + Диаметр + Производитель:Нагрузка  + Нагрузка:Диаметр, data=data2)
```

Сравним коэффициенты новой модели и модели 4:
```{r, echo=FALSE}
res <- cbind(coefficients(m4), coefficients(m5))
colnames(res) <- c("All data", "Filtered data")
res
```
Коэффициенты изменились несильно.

#### 11. Анализ модели 5
Остатки нормальны, несмещены, гетероскедастичны
```{r}
shapiro.test(residuals(m5))$p.value
t.test(residuals(m5))$p.value
as.numeric(bptest(m5)$p.value)
```

```{r fig.height=10, fig.width=10, warning=FALSE}
visualize_model(m5, data = data2)
```

#### Результат
Итоговая модель построена по `r dim(data2)[1]` из `r dim(data_orig)[1]` исходных объектов и объясняет `r round(100*summary(m5)$r.squared)`% вариации корня от L10:

Коэффициенты финальной модели:
```{r, echo=FALSE}
coefficients(m5)
```

```{r}
summary(m5)
```
Есть зависимость от: Производитель, Нагрузка, Диаметр

```{r}
confint(m5)
```

Распределение предсказания корня из L10 относительно истинной величины:
```{r}
par(mfrow=c(1,1))
plot(data2$newL10, fitted(m5), xlab="Sqrt L10", ylab="Predicted sqrt L10", pch=19)
lines(c(0,10), c(0,10), col="red")
grid()
```
Таким образом,

 * Каждая единица нагрузки уменьшает отклик на `r -coef(m5)["Нагрузка"]` (производитель 1)
 * Каждая единица нагрузки уменьшает отклик на `r -(coef(m5)["Нагрузка"]+coef(m5)["Нагрузка:Производитель2"])` (производитель 2)
 * Каждая единица нагрузки уменьшает отклик на `r -(coef(m5)["Нагрузка"]+coef(m5)["Нагрузка:Производитель3"])` (производитель 3)
 * Каждая единица диаметра увеличивает отклик на `r coef(m5)["Диаметр"]`
