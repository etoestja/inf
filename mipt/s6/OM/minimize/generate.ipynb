{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "Решаем задачу оптимизации $f(x)\\to\\underset{\\mathbb{R}^n}{\\min}$, где $f(x)=\\frac{1}{2}x^TAx-b^Tx$, причем матрица $A$ симметричная и положительно определенная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Библиотеки для работы с матрицами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание случайной матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$A=S^TDS$$\n",
    "S получается ортогонализацией Грамма-Шмидта из случайной матрицы, D задается явно ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Размерность пространства\n",
    "n=200\n",
    "# Случайная матрица\n",
    "S0=np.random.randn(n,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ортогонализация Грамма-Шмидта\n",
    "S=np.copy(S0)\n",
    "for i in range(n):\n",
    "    S[i] = np.copy(S0[i])\n",
    "    for j in range(i):\n",
    "        S[i] -= S[j] * np.dot(S[i], S[j]) / np.dot(S[j], S[j])\n",
    "    S[i] /= np.sqrt(np.dot(S[i], S[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем ортогональность\n",
    "np.allclose(np.dot(S.T,S), np.eye(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Собственные числа матрицы A\n",
    "D=np.diag(np.array(range(n)) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A=np.dot(S.T, np.dot(D, S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Вектор b\n",
    "b=np.random.rand(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Градиент функции\n",
    "def grad(A, b, x):\n",
    "    return(np.dot(A, x) - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция\n",
    "def func(A, b, x):\n",
    "    return(0.5 * np.dot(x.T, np.dot(A, x))-np.dot(b, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод 1. Градиентный спуск с постоянным шагом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=2039\n",
      "x=[ -8.296e-02   1.484e-01  -3.375e-02  -3.838e-02   1.239e-01  -1.048e-02\n",
      "   3.789e-02   1.790e-01   7.560e-02   5.463e-02  -1.657e-01  -3.649e-02\n",
      "   7.594e-02   8.739e-02   7.869e-02   1.461e-01   1.648e-01   3.763e-02\n",
      "  -1.944e-02   1.514e-01   6.304e-02   3.594e-02   1.622e-01   1.937e-01\n",
      "  -3.430e-02   1.432e-01   1.646e-01   6.088e-02   1.991e-01   5.471e-02\n",
      "   2.524e-02   6.235e-02   6.363e-02  -1.804e-01  -5.055e-02   1.405e-01\n",
      "  -8.321e-02   1.122e-01   2.292e-02  -1.027e-02  -3.840e-02   8.469e-02\n",
      "  -3.680e-02   1.423e-01   8.854e-02   7.533e-02   8.095e-02   6.162e-02\n",
      "  -1.342e-01  -6.872e-03   8.330e-02   3.884e-02   2.425e-02   6.353e-02\n",
      "   4.944e-02  -1.309e-01   3.641e-05   3.040e-02  -2.308e-02   8.492e-03\n",
      "   1.142e-01   1.301e-01   1.589e-01  -2.336e-02  -1.030e-01  -1.137e-02\n",
      "   9.848e-02   1.317e-01  -6.851e-02  -3.418e-02   1.376e-01   2.012e-01\n",
      "   4.231e-02   2.770e-02  -1.452e-02   2.943e-02  -2.753e-02  -4.002e-02\n",
      "   5.606e-02   1.117e-01  -1.518e-01   1.108e-01   2.463e-02   4.683e-02\n",
      "   1.710e-01  -3.808e-02   1.062e-01   7.436e-02   7.585e-02   1.761e-01\n",
      "  -1.833e-02   1.390e-01   4.590e-02  -9.539e-03   1.553e-01  -1.851e-01\n",
      "  -1.483e-02   1.446e-01  -1.785e-01   1.360e-01   2.875e-02  -5.531e-02\n",
      "  -8.467e-02   8.722e-02   1.711e-01   6.067e-03  -5.189e-02   8.963e-02\n",
      "  -1.015e-02   5.395e-02  -6.264e-02   3.333e-02   6.312e-03   1.018e-01\n",
      "   1.153e-01   1.731e-01  -1.754e-01   4.820e-02  -8.745e-02   1.012e-01\n",
      "   1.039e-01   4.989e-02  -4.721e-02  -1.303e-02   1.170e-01  -1.236e-01\n",
      "   3.326e-02  -6.482e-02   5.591e-02  -1.548e-01   1.217e-01  -3.134e-02\n",
      "  -4.012e-02   5.382e-02  -5.334e-02   1.115e-01   1.288e-02   7.136e-02\n",
      "   3.578e-02   8.278e-02   1.280e-01  -4.226e-02  -9.203e-02  -6.308e-02\n",
      "  -4.067e-02   3.177e-02  -6.163e-02  -4.230e-02   1.437e-01   7.137e-02\n",
      "   1.139e-01   9.338e-02  -3.434e-02  -2.804e-03   9.549e-02  -2.136e-02\n",
      "   3.707e-02  -5.123e-02   1.561e-01   1.451e-02   2.623e-01  -2.191e-02\n",
      "  -1.762e-02   1.364e-01  -7.147e-02   8.060e-02  -9.060e-02   1.147e-01\n",
      "  -1.350e-02   7.293e-02   1.227e-01   8.011e-02   5.018e-02  -1.934e-01\n",
      "   8.732e-02   1.355e-01   2.094e-01   7.928e-02  -3.123e-02   5.575e-02\n",
      "   9.595e-03  -1.166e-02   1.913e-02   2.558e-01  -2.956e-02   1.264e-01\n",
      "   9.101e-02   3.467e-02   1.132e-01  -2.770e-02  -8.001e-02   9.074e-05\n",
      "   4.577e-02  -1.354e-01   2.157e-01   5.586e-04  -1.524e-02   2.549e-02\n",
      "   1.460e-01   4.340e-02]\n",
      "func=-2.14609600409\n",
      "gradnorm=0.000249824694073\n",
      "norm(Ax-n)=0.00025\n"
     ]
    }
   ],
   "source": [
    "x=list()\n",
    "x.append(np.zeros(n))\n",
    "i = 1\n",
    "a=0.004\n",
    "\n",
    "x_norm=1e-6\n",
    "maxiter=10000\n",
    "\n",
    "while True:\n",
    "    x.append(0)\n",
    "    x[i] = x[i-1] - a * grad(A, b, x[i - 1])\n",
    "    #print x[i], func(A, b, x[i])\n",
    "    \n",
    "    if(linalg.norm(x[i]-x[i - 1]) < x_norm):\n",
    "        break\n",
    "    \n",
    "    if i >= maxiter:\n",
    "        break\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "print(\"i=%d\\nx=%s\\nfunc=%s\\ngradnorm=%s\" % (i, str(x[i - 1]),\n",
    "                                            str(func(A, b, x[i - 1])), str(linalg.norm(grad(A, b, x[i - 1])))))\n",
    "print(\"norm(Ax-n)=%0.2g\" % (linalg.norm(np.dot(A, x[i - 1]) - b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TODO:\n",
    "### Методы\n",
    "* Градиентный спуск\n",
    "* Субградиентный спуск\n",
    "* Метод Ньютона\n",
    "* Метод сопряженных градиентов\n",
    "\n",
    "### Критерии остановки\n",
    "не знаем $f(x^*)$\n",
    "\n",
    "по Поляку\n",
    "### Выбор шага\n",
    "По 2 методы на каждый элемент\n",
    "\n",
    "Армихо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
